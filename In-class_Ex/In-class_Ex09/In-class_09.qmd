---
title: "In-class Exercise 9"

execute:
  warning: false
  echo: true
  eval: true
  
date: "`r Sys.Date()`"
---

We will be focusing on the sfdep method instead of the spdep method that aws used in the hands on exercise

# Download R packages

```{r}
pacman::p_load(sp, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse, GGally, spdep)
```

# Importing data

## Geospatial data

```{r}
shan_sf <- st_read(dsn = "data/geospatial", 
                   layer = "myanmar_township_boundaries") %>%
  filter(ST %in% c("Shan (East)", "Shan (North)", "Shan (South)")) %>%
  select(c(2:7))
```

```{r}
# Returns the object type/class
class(shan_sf)

# similar to shan_sf
```

## Aspatial data

```{r}
# already been cleaned by prof so that it only includes Shan region
ict <- read_csv ("data/aspatial/Shan-ICT.csv")
```

```{r}
summary(ict)
```

## Derive new variables using **dplyr** package

```{r}
# standardized via scaling 
ict_derived <- ict %>%
  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%
  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%
  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%
  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%
  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%
  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%
  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,
         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,
         `TT_HOUSEHOLDS`=`Total households`,
         `RADIO`=`Radio`, `TV`=`Television`, 
         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,
         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) 
```

```{r}
summary(ict_derived)
```

# EDA

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```

Plotting newly derived variables

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

Building multiple plots / composite plot

```{r}
radio <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

tv <- ggplot(data=ict_derived, 
             aes(x= `TV_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

llphone <- ggplot(data=ict_derived, 
             aes(x= `LLPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

mphone <- ggplot(data=ict_derived, 
             aes(x= `MPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

computer <- ggplot(data=ict_derived, 
             aes(x= `COMPUTER_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

internet <- ggplot(data=ict_derived, 
             aes(x= `INTERNET_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

# arrange the composite plot together
ggarrange(radio, tv, llphone, mphone, computer, internet, 
          ncol = 3, 
          nrow = 2)
```

```{r}
shan_sf <- left_join(shan_sf, 
                     ict_derived, by=c("TS_PCODE"="TS_PCODE"))
  
write_rds(shan_sf, "data/rds/shan_sf.rds")
```

```{r}
shan_sf <- read_rds("data/rds/shan_sf.rds")
```

# Correlation analysis

```{r}
# correlogram and corplt --> similar to scatter plot but uses elipses
# shape of elipse; rounded = less correlated, narrow = highly correlated
# blue = positive, erd = negative

#returns a matrix
cluster_vars.cor = cor(ict_derived[,12:17])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

Drop either cmoputer or internet, because they are very highly correlated

## Hierarchy Cluster Analysis

## Extracting clustering variables

```{r}
# prepare data for cluster analysis
# must remove the geometry or there will be an error due to the way that clusters work

cluster_vars <- shan_sf %>%
  st_set_geometry(NULL) %>%
  select("TS.x", "RADIO_PR", "TV_PR", "LLPHONE_PR", "MPHONE_PR", "COMPUTER_PR")
head(cluster_vars,10)
```

There is no row name right now, so we are going to make the town name into a row name.

```{r}
row.names(cluster_vars) <- cluster_vars$"TS.x"
head(cluster_vars,10)
```

```{r}
shan_ict <- select(cluster_vars, c(2:6))
head(shan_ict, 10)
```

## Data Standardisation

In general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.

## Min-Max standardisation

```{r}
# min-max always 0 to 1
shan_ict.std <- normalize(shan_ict)
summary(shan_ict.std)
```

## Z-score standardisation

```{r}
# min max varies, but std_d is always 1 and mean is always 0
shan_ict.z <- scale(shan_ict)
describe(shan_ict.z)
```

## Visualising the standardised clustering variables

```{r}
# the main difference is in the data range

r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

# Calculating proximity matrix

```{r}
# take the tidied one and clean with a distance method
proxmat <- dist(shan_ict, method = 'euclidean')
```

```{r}
#| eval: false
#| echo: false

proxmat
```

## Computing hierarchical clustering

```{r}
# MUST use a dist object class for hclust function to run

hclust_ward <- hclust(proxmat, method = 'ward.D')
```

Tree plot:

```{r}
# this dendrogram is without grouping
# it is able to tell you at what distance will each township merge together
plot(hclust_ward, cex = 0.6)
```

## Selecting the optimal clustering algorithm

The code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(shan_ict, method = x)$ac
}

map_dbl(m, ac)
```

With reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed (closest to 1). Hence, in the subsequent analysis, only Ward’s method will be used.

## Determining Optimal Clusters

There are [three](https://statweb.stanford.edu/~gwalther/gap) commonly used methods to determine the optimal clusters, they are:

-   [Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering))

-   [Average Silhouette Method](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub)

-   [Gap Statistic Method](http://www.web.stanford.edu/~hastie/Papers/gap.pdf)

### Gap statistic

```{r}
set.seed(12345)
gap_stat <- clusGap(shan_ict, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
# read the gap specifically
print(gap_stat, method = "firstmax")
```

```{r}
# beware local optimization
fviz_gap_stat(gap_stat)
```

## Interpreting the dendrograms

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```

## Visually-driven hierarchical clustering analysis

### Transforming the data frame into a matrix

```{r}
shan_ict_mat <- data.matrix(shan_ict)
```

### Plotting interactive cluster heatmap using *heatmaply()*

```{r}
heatmaply(normalize(shan_ict_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 6,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Shan State by ICT indicators",
          xlab = "ICT Indicators",
          ylab = "Townships of Shan State"
          )
```

## Mapping the clusters formed

```{r}
#as.factor converts the numerical numbering of clusters to a factor data type (ordinal/nominal scale)
groups <- as.factor(cutree(hclust_ward, k=6))
```

In order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.

The code chunk below form the join in three steps:

-   the *groups* list object will be converted into a matrix;

-   *cbind()* is used to append *groups* matrix onto shan_sf to produce an output simple feature object called `shan_sf_cluster`; and

-   *rename* of **dplyr** package is used to rename *as.matrix.groups* field as *CLUSTER*.

```{r}
# if we did any sorting, it is not safe to bind these together
# cbind is a COLUMN APPEND, so you cannot sort the data at all
shan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

```{r}
# note that this is not the end of the cluster analysis, there is also multivariate visualisation to know the characteristics of the cluster
qtm(shan_sf_cluster, "CLUSTER")
```

# Spatially Constrained Clustering: SKATER approach

Do NOT convert to SpatialPolygonsDataFrame, it is no longer needed. We can skip straight to the next code, as the latest version of spdep can accept sf features.

```{r}
shan.nb <- poly2nb(shan_sf)
summary(shan.nb)
```

Plotting the map using sf data object.

```{r}
# plot the background first before plotting the links over top of it

#REMEMBER st_geometry so that only one output layer will be outputted
plot(st_geometry(shan_sf), 
     border=grey(.5))

pts <- st_coordinates(st_centroid(shan_sf)) # gives all the centroid nodes
plot(shan.nb, 
     pts, 
     col="blue", 
     add=TRUE)
```

## Computing minimum spanning tree

### Calculating edge costs

Compute the cost of each edge

```{r}
lcosts <- nbcosts(shan.nb, shan_ict)
```

```{r}
shan.w <- nb2listw(shan.nb, 
                   lcosts, 
                   style="B")
summary(shan.w)
```

## Computing minimum spanning tree

```{r}
shan.mst <- mstree(shan.w)
```

```{r}
class(shan.mst)
```

```{r}
dim(shan.mst)
```

```{r}
head(shan.mst)
```

```{r}
plot(st_geometry(shan_sf), 
     border=grey(.5))

plot.mst(shan.mst, 
         pts, 
         col="blue", 
         cex.lab=0.7, 
         cex.circles=0.005, 
         add=TRUE)
```
