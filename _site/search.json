[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this study, we apply appropriate spatial point patterns analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore and describe the spatial patterns revealed by kernel density maps."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Aspatial data",
    "text": "Aspatial data\n\nGrab Posisi data\nFirst, the data needs to be imported into RStudio. In this exercise, we will need to import all of the data in order to observe the temporal distribution.\n\ndf <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00000.parquet\")\ndf1 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00001.parquet\")\ndf2 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00002.parquet\")\ndf3 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00003.parquet\")\ndf4 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00004.parquet\")\ndf5 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00005.parquet\")\ndf6 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00006.parquet\")\ndf7 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00007.parquet\")\ndf8 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00008.parquet\")\ndf9 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00009.parquet\")\n\n\nCombining the data\nAll of the data covers 2 weeks of Grab rides, but they are jumbled up. In order to accurately extract the origin and destination points, we need to combine everything into a singular data frame.\n\nall_grab <- df %>%\n  full_join(df1) %>%\n  full_join(df2) %>%\n  full_join(df3) %>%\n  full_join(df4) %>%\n  full_join(df5) %>%\n  full_join(df6) %>%\n  full_join(df7) %>%\n  full_join(df8) %>%\n  full_join(df9)\n\n\n\nData handling: Converting the data type of pingtimestamp to date-time\nGrab marks the date-time of each data point as a pingtimestamp. As a result, we will need to transform the data type to date-time using lubridate.\n\nall_grab$pingtimestamp <- as_datetime(all_grab$pingtimestamp)\n\n\n\nData handling: Extracting trip origins\nNow, we extract the trip origin locations and derive 3 new columns for weekday, starting hour and day of month into a new data frame. The origin locations are derived by grouping trips according to their trj_id, arranging by the date-time and filtering for the first item in each group.\n\norigin_df <- all_grab %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label = TRUE,\n                        abbr = TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\nData handling: Extracting destinations\nTo extract trip destinations, we use a similar code as above except we filter to take the nth item out of n items in a group.\n\ndest_df <- all_grab %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==n()) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label = TRUE,\n                        abbr = TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\nWriting data as rds\nWith the data transformation done, we can now write it out as an rds for future use.\n\nwrite_rds(origin_df, \"data/rds/grab_origins.rds\")\nwrite_rds(dest_df, \"data/rds/grab_dest.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Geospatial data",
    "text": "Geospatial data\n\nSingapore Coastal outline (excluding islands)\nThis layer is derived from the Master Plan 2019 Subzone Boundary (No Sea) from data.gov. First, it needs to be imported into rstudio using st_read()\n\nmpsz_sf <- st_read(dsn = \"data/geospatial\", \n                layer = \"MPSZ-2019\")\n\nFrom the summary, it can be seen that the layer is projected to WGS84. To continue, there is the need to reproject the polygons to the correct CRS SVY21.\n\nmpsz3414_sf <- st_transform(mpsz_sf, 3414)\n\nNow, we can plot the map and view the data.\n\nplot(mpsz3414_sf[\"SUBZONE_N\"])\n\nThere are some islands in the map that lack bridges for Grab drivers to reach, such as Coney Island. However, there are other relevant islands such as Sentosa that need to be kept.\nFrom research, Grab drivers can be observed to be able to enter Sentosa and Jurong Island to pick up and drop off passengers at the current moment. However, the Jurong Island polygon in mpsz3414_sf is combined with another island Bukom. Furthermore, Grab drivers are only allowed onto the island if they have a security pass, resulting in few drivers entering and exiting the island. Therefore, I am choosing to remove Jurong Island and Bukom from the map.\nHence, the islands that need to be excluded from the map are:\n\nConey Island\nSouthern Group\nNorth-Eastern islands (including Pulau Ubin: Grab drivers can only pick up and drop off passengers at the ferry terminal)\nSudong\nSemakau\nJurong Island and Bukom\n\nTo remove these, I’ve chosen to filter them out by name. This is because Sentosa and Jurong Island are also labelled as “islands” and would otherwise be caught.\n\nmain_island <- mpsz3414_sf %>%\n              filter(SUBZONE_N !=\"CONEY ISLAND\") %>%\n              filter(SUBZONE_N != \"NORTH-EASTERN ISLANDS\") %>%\n              filter(SUBZONE_N != \"SOUTHERN GROUP\") %>%\n              filter(SUBZONE_N != \"SUDONG\") %>%\n              filter(SUBZONE_N != \"SEMAKAU\") %>%\n              filter(SUBZONE_N != \"SUDONG\") %>%\n              filter(SUBZONE_N != \"JURONG ISLAND AND BUKOM\")\n\nplot(main_island[\"SUBZONE_N\"])\n\nNow, we can use st_union to get the outline of Singapore.\n\nplot(st_union(main_island))\n\n\nWriting data as rds\nWith this, we can now save the data in the rds format.\n\nwrite_rds(main_island, \"data/rds/islandOutline.rds\")\n\n\n\n\nSingapore road network\nIn order to conduct Network Kernel Density Estimation (NKDE), we will need a road network to map points onto. For Singapore’s road network, we can get data from OpenStreetMap via Geofabrik. From the documentation that comes with the download, we know that the road network is found in the gis_osm_roads_free_1 shape file.\n\nroads_all <- st_read(dsn = \"data/geospatial/openstreetmap\", \n                layer = \"gis_osm_roads_free_1\")\n\nThis data is also not projected to SVY21, which is something we will have to fix.\n\nroads_all <- st_transform(roads_all, 3414)\n\nOne issue currently is that the data includes all roads from Singapore, Malaysia and Brunei. We only want the road network for Singapore. In order to extract this, we can use st_intersection to filter for roads within Singapore based on the CoastalOutline layer (as imported from rds)\n\nsg_roads <- st_intersection(roads_all, CoastalOutline)\n\nDue to the size of the data, we will later be narrowing the scope of our investigation for NKDE to certain subzones. For now, I will save the current road network into an rds.\n\nwrite_rds(sg_roads, \"data/rds/sgroads.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-of-origins",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-of-origins",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Analysis of origins",
    "text": "Analysis of origins\nFirst, lets look at the distribution of origins over time using ggplot.\n\nggplot(data = origin_all_df,\n       aes(x=weekday)) +\ngeom_bar()\n\n\n\n\nAs seen above, the data is evenly distributed across all days of the week.\n\nppp object transformation\nIn order to conduct Kernel Density Estimation (KDE), we need to transform our layers into a ppp object. Before we begin that process, we will need to transform origin_all_df into an sf object using st_as_sf().\n\n\n\n\n\n\nImportant\n\n\n\nFor the “crs” argument of st_as_sf(), we need to provide it with a geodetic CRS and not a projected CRS. To transform the CRS, we can pipe the output into an st_transform() argument.\n\n\n\norigins_sf <- st_as_sf(origin_all_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\nNow, we can transform all relevant data frames into a ppp object (via transforming to Spatial/*, SpatialPoints and then ppp objects), which we can inspect using the summary function.\n\norigin_spatial <- as_Spatial(origins_sf)\norigin_sp <- as(origin_spatial, \"SpatialPoints\")\norigin_ppp <- as(origin_sp, \"ppp\")\n\nsummary(origin_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units\n\n\n\n\nDuplicate data handling\nNow, we need to check for duplicated data.\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\n\nIf we want to know how many locations have more than one point event, we can use the following:\n\nsum(multiplicity(origin_ppp) > 1)\n\n[1] 0\n\n\nAs we can see, there is no duplicate data in the ppp object.\n\n\nCreating owin object\nNext, we need to confine the analysis with a geographical area like Singapore boundary. If a study area is not defined and confined, the data points will assume it can occur within blank spaces (because technically it will spread out at random).\n\nCoastalOutline <- st_union(CoastalOutline)\nsg_owin <- as.owin(CoastalOutline)\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            13910  6.66691e+08      9.98e-01\npolygon 2              285  1.61128e+06      2.41e-03\npolygon 3               27  1.50315e+04      2.25e-05\npolygon 4 (hole)        41 -4.01660e+04     -6.01e-05\npolygon 5 (hole)       317 -5.11280e+04     -7.65e-05\npolygon 6 (hole)         3 -4.14099e-04     -6.20e-13\npolygon 7               30  2.80002e+04      4.19e-05\npolygon 8 (hole)         4 -2.86396e-01     -4.29e-10\npolygon 9 (hole)         3 -1.81439e-04     -2.71e-13\npolygon 10 (hole)        3 -8.68789e-04     -1.30e-12\npolygon 11 (hole)        3 -5.99535e-04     -8.97e-13\npolygon 12 (hole)        3 -3.04561e-04     -4.56e-13\npolygon 13 (hole)        3 -4.46076e-04     -6.67e-13\npolygon 14 (hole)        3 -3.39794e-04     -5.08e-13\npolygon 15 (hole)        3 -4.52043e-05     -6.76e-14\npolygon 16 (hole)        3 -3.90173e-05     -5.84e-14\npolygon 17 (hole)        3 -9.59850e-05     -1.44e-13\npolygon 18 (hole)        4 -2.54488e-04     -3.81e-13\npolygon 19 (hole)        4 -4.28453e-01     -6.41e-10\npolygon 20 (hole)        4 -2.18616e-04     -3.27e-13\npolygon 21 (hole)        5 -2.44411e-04     -3.66e-13\npolygon 22 (hole)        5 -3.64686e-02     -5.46e-11\npolygon 23              71  8.18750e+03      1.23e-05\npolygon 24 (hole)        6 -8.37554e-01     -1.25e-09\npolygon 25 (hole)       38 -7.79904e+03     -1.17e-05\npolygon 26 (hole)        3 -3.41897e-05     -5.12e-14\npolygon 27 (hole)        3 -3.65499e-03     -5.47e-12\npolygon 28 (hole)        3 -4.95057e-02     -7.41e-11\npolygon 29              91  1.49663e+04      2.24e-05\npolygon 30 (hole)        5 -2.92235e-04     -4.37e-13\npolygon 31 (hole)        3 -7.43616e-06     -1.11e-14\npolygon 32 (hole)      270 -1.21455e+03     -1.82e-06\npolygon 33 (hole)       19 -4.39650e+00     -6.58e-09\npolygon 34 (hole)       35 -1.38385e+02     -2.07e-07\npolygon 35 (hole)       23 -1.99656e+01     -2.99e-08\npolygon 36              40  1.38607e+04      2.07e-05\npolygon 37 (hole)       41 -6.00381e+03     -8.98e-06\npolygon 38 (hole)        7 -1.40546e-01     -2.10e-10\npolygon 39 (hole)       11 -8.36705e+01     -1.25e-07\npolygon 40 (hole)        3 -2.33435e-03     -3.49e-12\npolygon 41              45  2.51218e+03      3.76e-06\npolygon 42             139  3.22293e+03      4.82e-06\npolygon 43             148  3.10395e+03      4.64e-06\npolygon 44 (hole)        4 -1.72650e-04     -2.58e-13\npolygon 45              75  1.73526e+04      2.60e-05\npolygon 46              83  5.28920e+03      7.91e-06\npolygon 47             106  3.04104e+03      4.55e-06\npolygon 48              71  5.63061e+03      8.43e-06\npolygon 49              10  1.99717e+02      2.99e-07\npolygon 50 (hole)        3 -1.37223e-02     -2.05e-11\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units\n                     (53270 x 28810 units)\nWindow area = 668316000 square units\nFraction of frame area: 0.435\n\n\nWith that, we can finally plot the point data onto the map.\n\noriginSG = origin_ppp[sg_owin]\n\nplot(originSG)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-values",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Rescaling values",
    "text": "Rescaling values\nBefore we can conduct KDE analysis, we first need to rescale the unit of measurement in originSG from metres (the unit of measurement in SVY21) to kilometres (to avoid small numbers).\n\noriginSG_km <- rescale(originSG, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-bandwidth-selection-methods",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-bandwidth-selection-methods",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Working with different automatic bandwidth selection methods",
    "text": "Working with different automatic bandwidth selection methods\nThere are 4 different automatic bandwidth selection method that we can choose: bw.diggle, bw.CvL, bw.scott and bw.ppl. For this exercise, we are using bw.diggle, or the radius selection method. We can plot all four to see which may give us better results.\n\nkde_origins_dig <- density(originSG_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nkde_origins_ppl <- density(originSG_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nkde_origins_cvl <- density(originSG_km,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nkde_origins_scott <- density(originSG_km,\n                              sigma=bw.scott,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\npar(mfrow=c(2,2))\nplot(kde_origins_dig, main = \"bw.diggle\")\nplot(kde_origins_ppl, main = \"bw.ppl\")\nplot(kde_origins_cvl, main = \"bw.cvl\")\nplot(kde_origins_scott, main = \"bw.scott\")\n\n\n\n\nWe can retrieve the bandwidth used to compute the KDE layer as well.\n\nbw.diggle(originSG)\n\n   sigma \n8.091242 \n\nbw.ppl(originSG)\n\n   sigma \n123.8747 \n\nbw.CvL(originSG)\n\n   sigma \n3147.573 \n\nbw.scott(originSG)\n\n  sigma.x   sigma.y \n1592.5974  938.9125 \n\n\nAs seen, bw.ppl and bw.diggle appears to give relatively similar map results which highlight a single tight cluster in the east and include up to a thousand origin points. Meanwhile, bw.cvl and bw.scott appear to use tighter radii, with bw.scott being able to better show hotspots compared to how spread out bw.cvl looks. Hence, for the rest of this exercise, we will be using bw.scott."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-kernel-methods",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-kernel-methods",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Working with different kernel methods",
    "text": "Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics. We can test each of these to see which kernel method provides a tighter grouping.\n\npar(mfrow=c(2,2))\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\nFor this exercise, disc and quartic appear to provide us with tighter values. Hence, we will be using Disc."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-to-raster-via-grid-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-to-raster-via-grid-object",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Conversion to raster via grid object",
    "text": "Conversion to raster via grid object\nIn order to fully visualise KDE in tmap, we would need to transform it into raster data. Before that, we need to convert it into a grid object\n\ngridded_kde_origins_bw <- as.SpatialGridDataFrame.im(kde_originSG_600)\nspplot(gridded_kde_origins_bw)\n\n\n\n\nNow, we can convert it to raster data.\n\nkde_originsSG_bw_raster <- raster(gridded_kde_origins_bw)\n\nNote that there is no CRS to this data, so we will need to assign it on our own\n\nprojection(kde_originsSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_originsSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.173372e-13, 353.656  (min, max)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-kde-tmap",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-kde-tmap",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Visualising KDE (tmap)",
    "text": "Visualising KDE (tmap)"
  }
]