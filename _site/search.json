[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this study, we apply appropriate spatial point patterns analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore and describe the spatial patterns revealed by kernel density maps."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Aspatial data",
    "text": "Aspatial data\n\nGrab Posisi data\nFirst, the data needs to be imported into RStudio. In this exercise, we will need to import all of the data in order to observe the temporal distribution.\n\ndf <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00000.parquet\")\ndf1 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00001.parquet\")\ndf2 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00002.parquet\")\ndf3 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00003.parquet\")\ndf4 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00004.parquet\")\ndf5 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00005.parquet\")\ndf6 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00006.parquet\")\ndf7 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00007.parquet\")\ndf8 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00008.parquet\")\ndf9 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00009.parquet\")\n\n\nCombining the data\nAll of the data covers 2 weeks of Grab rides, but they are jumbled up. In order to accurately extract the origin and destination points, we need to combine everything into a singular data frame.\n\nall_grab <- df %>%\n  full_join(df1) %>%\n  full_join(df2) %>%\n  full_join(df3) %>%\n  full_join(df4) %>%\n  full_join(df5) %>%\n  full_join(df6) %>%\n  full_join(df7) %>%\n  full_join(df8) %>%\n  full_join(df9)\n\n\n\nData handling: Converting the data type of pingtimestamp to date-time\nGrab marks the date-time of each data point as a pingtimestamp. As a result, we will need to transform the data type to date-time using lubridate.\n\nall_grab$pingtimestamp <- as_datetime(all_grab$pingtimestamp)\n\n\n\nData handling: Extracting trip origins\nNow, we extract the trip origin locations and derive 3 new columns for weekday, starting hour and day of month into a new data frame. The origin locations are derived by grouping trips according to their trj_id, arranging by the date-time and filtering for the first item in each group.\n\norigin_df <- all_grab %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label = TRUE,\n                        abbr = TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\nData handling: Extracting destinations\nTo extract trip destinations, we use a similar code as above except we filter to take the nth item out of n items in a group.\n\ndest_df <- all_grab %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==n()) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label = TRUE,\n                        abbr = TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\nWriting data as rds\nWith the data transformation done, we can now write it out as an rds for future use.\n\nwrite_rds(origin_df, \"data/rds/grab_origins.rds\")\nwrite_rds(dest_df, \"data/rds/grab_dest.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Geospatial data",
    "text": "Geospatial data\n\nSingapore Coastal outline (excluding islands)\nThis layer is derived from the Master Plan 2019 Subzone Boundary (No Sea) from data.gov. First, it needs to be imported into rstudio using st_read()\n\nmpsz_sf <- st_read(dsn = \"data/geospatial\", \n                layer = \"MPSZ-2019\")\n\nFrom the summary, it can be seen that the layer is projected to WGS84. To continue, there is the need to reproject the polygons to the correct CRS SVY21.\n\nmpsz3414_sf <- st_transform(mpsz_sf, 3414)\n\nNow, we can plot the map and view the data.\n\nplot(mpsz3414_sf[\"SUBZONE_N\"])\n\nThere are some islands in the map that lack bridges for Grab drivers to reach, such as Coney Island. However, there are other relevant islands such as Sentosa that need to be kept.\nFrom research, Grab drivers can be observed to be able to enter Sentosa and Jurong Island to pick up and drop off passengers at the current moment. However, the Jurong Island polygon in mpsz3414_sf is combined with another island Bukom. Furthermore, Grab drivers are only allowed onto the island if they have a security pass, resulting in few drivers entering and exiting the island. Therefore, I am choosing to remove Jurong Island and Bukom from the map.\nHence, the islands that need to be excluded from the map are:\n\nConey Island\nSouthern Group\nNorth-Eastern islands (including Pulau Ubin: Grab drivers can only pick up and drop off passengers at the ferry terminal)\nSudong\nSemakau\nJurong Island and Bukom\n\nTo remove these, I’ve chosen to filter them out by name. This is because Sentosa and Jurong Island are also labelled as “islands” and would otherwise be caught.\n\nmain_island <- mpsz3414_sf %>%\n              filter(SUBZONE_N !=\"CONEY ISLAND\") %>%\n              filter(SUBZONE_N != \"NORTH-EASTERN ISLANDS\") %>%\n              filter(SUBZONE_N != \"SOUTHERN GROUP\") %>%\n              filter(SUBZONE_N != \"SUDONG\") %>%\n              filter(SUBZONE_N != \"SEMAKAU\") %>%\n              filter(SUBZONE_N != \"SUDONG\") %>%\n              filter(SUBZONE_N != \"JURONG ISLAND AND BUKOM\")\n\nplot(main_island[\"SUBZONE_N\"])\n\nNow, we can use st_union to get the outline of Singapore.\n\nplot(st_union(main_island))\n\n\nWriting data as rds\nWith this, we can now save the data in the rds format.\n\nwrite_rds(main_island, \"data/rds/islandOutline.rds\")\n\n\n\n\nSingapore road network\nIn order to conduct Network Kernel Density Estimation (NKDE), we will need a road network to map points onto. For Singapore’s road network, we can get data from OpenStreetMap via Geofabrik. From the documentation that comes with the download, we know that the road network is found in the gis_osm_roads_free_1 shape file.\n\nroads_all <- st_read(dsn = \"data/geospatial/openstreetmap\", \n                layer = \"gis_osm_roads_free_1\")\n\nThis data is also not projected to SVY21, which is something we will have to fix.\n\nroads_all <- st_transform(roads_all, 3414)\n\nOne issue currently is that the data includes all roads from Singapore, Malaysia and Brunei. We only want the road network for Singapore. In order to extract this, we can use st_intersection to filter for roads within Singapore based on the CoastalOutline layer (as imported from rds)\n\nsg_roads <- st_intersection(roads_all, CoastalOutline)\n\nDue to the size of the data, we will later be narrowing the scope of our investigation for NKDE to certain subzones. For now, I will save the current road network into an rds.\n\nwrite_rds(sg_roads, \"data/rds/sgroads.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-of-origins",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-of-origins",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Analysis of origins",
    "text": "Analysis of origins\nFirst, lets look at the distribution of origins over time using ggplot.\n\nggplot(data = origin_all_df,\n       aes(x=weekday)) +\ngeom_bar()\n\n\n\n\nAs seen above, the data is evenly distributed across all days of the week.\n\nppp object transformation\nIn order to conduct Kernel Density Estimation (KDE), we need to transform our layers into a ppp object. Before we begin that process, we will need to transform origin_all_df into an sf object using st_as_sf().\n\n\n\n\n\n\nImportant\n\n\n\nFor the “crs” argument of st_as_sf(), we need to provide it with a geodetic CRS and not a projected CRS. To transform the CRS, we can pipe the output into an st_transform() argument.\n\n\n\norigins_sf <- st_as_sf(origin_all_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\nNow, we can transform all relevant data frames into a ppp object (via transforming to Spatial/*, SpatialPoints and then ppp objects), which we can inspect using the summary function.\n\norigin_spatial <- as_Spatial(origins_sf)\norigin_sp <- as(origin_spatial, \"SpatialPoints\")\norigin_ppp <- as(origin_sp, \"ppp\")\n\nsummary(origin_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units\n\n\n\n\nDuplicate data handling\nNow, we need to check for duplicated data.\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\n\nIf we want to know how many locations have more than one point event, we can use the following:\n\nsum(multiplicity(origin_ppp) > 1)\n\n[1] 0\n\n\nAs we can see, there is no duplicate data in the ppp object.\n\n\nCreating owin object\nNext, we need to confine the analysis with a geographical area like Singapore boundary. If a study area is not defined and confined, the data points will assume it can occur within blank spaces (because technically it will spread out at random).\n\nCoastalOutline <- st_union(CoastalOutline)\nsg_owin <- as.owin(CoastalOutline)\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            13910  6.66691e+08      9.98e-01\npolygon 2              285  1.61128e+06      2.41e-03\npolygon 3               27  1.50315e+04      2.25e-05\npolygon 4 (hole)        41 -4.01660e+04     -6.01e-05\npolygon 5 (hole)       317 -5.11280e+04     -7.65e-05\npolygon 6 (hole)         3 -4.14099e-04     -6.20e-13\npolygon 7               30  2.80002e+04      4.19e-05\npolygon 8 (hole)         4 -2.86396e-01     -4.29e-10\npolygon 9 (hole)         3 -1.81439e-04     -2.71e-13\npolygon 10 (hole)        3 -8.68789e-04     -1.30e-12\npolygon 11 (hole)        3 -5.99535e-04     -8.97e-13\npolygon 12 (hole)        3 -3.04561e-04     -4.56e-13\npolygon 13 (hole)        3 -4.46076e-04     -6.67e-13\npolygon 14 (hole)        3 -3.39794e-04     -5.08e-13\npolygon 15 (hole)        3 -4.52043e-05     -6.76e-14\npolygon 16 (hole)        3 -3.90173e-05     -5.84e-14\npolygon 17 (hole)        3 -9.59850e-05     -1.44e-13\npolygon 18 (hole)        4 -2.54488e-04     -3.81e-13\npolygon 19 (hole)        4 -4.28453e-01     -6.41e-10\npolygon 20 (hole)        4 -2.18616e-04     -3.27e-13\npolygon 21 (hole)        5 -2.44411e-04     -3.66e-13\npolygon 22 (hole)        5 -3.64686e-02     -5.46e-11\npolygon 23              71  8.18750e+03      1.23e-05\npolygon 24 (hole)        6 -8.37554e-01     -1.25e-09\npolygon 25 (hole)       38 -7.79904e+03     -1.17e-05\npolygon 26 (hole)        3 -3.41897e-05     -5.12e-14\npolygon 27 (hole)        3 -3.65499e-03     -5.47e-12\npolygon 28 (hole)        3 -4.95057e-02     -7.41e-11\npolygon 29              91  1.49663e+04      2.24e-05\npolygon 30 (hole)        5 -2.92235e-04     -4.37e-13\npolygon 31 (hole)        3 -7.43616e-06     -1.11e-14\npolygon 32 (hole)      270 -1.21455e+03     -1.82e-06\npolygon 33 (hole)       19 -4.39650e+00     -6.58e-09\npolygon 34 (hole)       35 -1.38385e+02     -2.07e-07\npolygon 35 (hole)       23 -1.99656e+01     -2.99e-08\npolygon 36              40  1.38607e+04      2.07e-05\npolygon 37 (hole)       41 -6.00381e+03     -8.98e-06\npolygon 38 (hole)        7 -1.40546e-01     -2.10e-10\npolygon 39 (hole)       11 -8.36705e+01     -1.25e-07\npolygon 40 (hole)        3 -2.33435e-03     -3.49e-12\npolygon 41              45  2.51218e+03      3.76e-06\npolygon 42             139  3.22293e+03      4.82e-06\npolygon 43             148  3.10395e+03      4.64e-06\npolygon 44 (hole)        4 -1.72650e-04     -2.58e-13\npolygon 45              75  1.73526e+04      2.60e-05\npolygon 46              83  5.28920e+03      7.91e-06\npolygon 47             106  3.04104e+03      4.55e-06\npolygon 48              71  5.63061e+03      8.43e-06\npolygon 49              10  1.99717e+02      2.99e-07\npolygon 50 (hole)        3 -1.37223e-02     -2.05e-11\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units\n                     (53270 x 28810 units)\nWindow area = 668316000 square units\nFraction of frame area: 0.435\n\n\nWith that, we can finally plot the point data onto the map.\n\noriginSG = origin_ppp[sg_owin]\n\nplot(originSG)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-values",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Rescaling values",
    "text": "Rescaling values\nBefore we can conduct KDE analysis, we first need to rescale the unit of measurement in originSG from metres (the unit of measurement in SVY21) to kilometres (to avoid small numbers).\n\noriginSG_km <- rescale(originSG, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-bandwidth-selection-methods",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-bandwidth-selection-methods",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Working with different automatic bandwidth selection methods",
    "text": "Working with different automatic bandwidth selection methods\nThere are 4 different automatic bandwidth selection method that we can choose: bw.diggle, bw.CvL, bw.scott and bw.ppl. For this exercise, we are using bw.diggle, or the radius selection method. We can plot all four to see which may give us better results.\n\nkde_origins_dig <- density(originSG_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nkde_origins_ppl <- density(originSG_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nkde_origins_cvl <- density(originSG_km,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nkde_origins_scott <- density(originSG_km,\n                              sigma=bw.scott,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\npar(mfrow=c(2,2))\nplot(kde_origins_dig, main = \"bw.diggle\")\nplot(kde_origins_ppl, main = \"bw.ppl\")\nplot(kde_origins_cvl, main = \"bw.cvl\")\nplot(kde_origins_scott, main = \"bw.scott\")\n\n\n\n\nWe can retrieve the bandwidth used to compute the KDE layer as well.\n\nbw.diggle(originSG)\nbw.ppl(originSG)\nbw.CvL(originSG)\nbw.scott(originSG)\n\nAs seen, bw.ppl and bw.diggle appears to give relatively similar map results which highlight a single tight cluster in the east and include up to a thousand origin points. Meanwhile, bw.cvl and bw.scott appear to use tighter radii, with bw.scott being able to better show hotspots compared to how spread out bw.cvl looks. Hence, for the rest of this exercise, we will be using bw.scott."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-kernel-methods",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-kernel-methods",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Working with different kernel methods",
    "text": "Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics. We can test each of these to see which kernel method provides a tighter grouping.\n\npar(mfrow=c(2,2))\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\nFor this exercise, disc and quartic appear to provide us with tighter values. Hence, we will be using Disc."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-to-raster-via-grid-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-to-raster-via-grid-object",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Conversion to raster via grid object",
    "text": "Conversion to raster via grid object\nIn order to fully visualise KDE in tmap, we would need to transform it into raster data. Before that, we need to convert it into a grid object\n\ngridded_kde_origins_bw <- as.SpatialGridDataFrame.im(kde_originSG_600)\nspplot(gridded_kde_origins_bw)\n\n\n\n\nNow, we can convert it to raster data.\n\nkde_originsSG_bw_raster <- raster(gridded_kde_origins_bw)\n\nNote that there is no CRS to this data, so we will need to assign it on our own\n\nprojection(kde_originsSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_originsSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.173372e-13, 353.656  (min, max)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-kde-tmap",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-kde-tmap",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Visualising KDE (tmap)",
    "text": "Visualising KDE (tmap)\n\ntm_shape(kde_originsSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#ppp-object-transformation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#ppp-object-transformation",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "ppp object transformation",
    "text": "ppp object transformation\nIn order to conduct Kernel Density Estimation (KDE), we need to transform our layers into a ppp object. Before we begin that process, we will need to transform origin_all_df into an sf object using st_as_sf().\n\n\n\n\n\n\nImportant\n\n\n\nFor the “crs” argument of st_as_sf(), we need to provide it with a geodetic CRS and not a projected CRS. To transform the CRS, we can pipe the output into an st_transform() argument.\n\n\n\norigins_sf <- st_as_sf(origin_all_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\nNow, we can transform all relevant data frames into a ppp object (via transforming to Spatial/*, SpatialPoints and then ppp objects), which we can inspect using the summary function.\n\norigin_spatial <- as_Spatial(origins_sf)\norigin_sp <- as(origin_spatial, \"SpatialPoints\")\norigin_ppp <- as(origin_sp, \"ppp\")\n\nsummary(origin_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#duplicate-data-handling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#duplicate-data-handling",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Duplicate data handling",
    "text": "Duplicate data handling\nNow, we need to check for duplicated data.\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\n\nIf we want to know how many locations have more than one point event, we can use the following:\n\nsum(multiplicity(origin_ppp) > 1)\n\n[1] 0\n\n\nAs we can see, there is no duplicate data in the ppp object."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-owin-object",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Creating owin object",
    "text": "Creating owin object\nNext, we need to confine the analysis with a geographical area like Singapore boundary. If a study area is not defined and confined, the data points will assume it can occur within blank spaces (because technically it will spread out at random).\n\nCoastalOutlineSG <- st_union(CoastalOutline)\nsg_owin <- as.owin(CoastalOutlineSG)\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            13910  6.66691e+08      9.98e-01\npolygon 2              285  1.61128e+06      2.41e-03\npolygon 3               27  1.50315e+04      2.25e-05\npolygon 4 (hole)        41 -4.01660e+04     -6.01e-05\npolygon 5 (hole)       317 -5.11280e+04     -7.65e-05\npolygon 6 (hole)         3 -4.14099e-04     -6.20e-13\npolygon 7               30  2.80002e+04      4.19e-05\npolygon 8 (hole)         4 -2.86396e-01     -4.29e-10\npolygon 9 (hole)         3 -1.81439e-04     -2.71e-13\npolygon 10 (hole)        3 -8.68789e-04     -1.30e-12\npolygon 11 (hole)        3 -5.99535e-04     -8.97e-13\npolygon 12 (hole)        3 -3.04561e-04     -4.56e-13\npolygon 13 (hole)        3 -4.46076e-04     -6.67e-13\npolygon 14 (hole)        3 -3.39794e-04     -5.08e-13\npolygon 15 (hole)        3 -4.52043e-05     -6.76e-14\npolygon 16 (hole)        3 -3.90173e-05     -5.84e-14\npolygon 17 (hole)        3 -9.59850e-05     -1.44e-13\npolygon 18 (hole)        4 -2.54488e-04     -3.81e-13\npolygon 19 (hole)        4 -4.28453e-01     -6.41e-10\npolygon 20 (hole)        4 -2.18616e-04     -3.27e-13\npolygon 21 (hole)        5 -2.44411e-04     -3.66e-13\npolygon 22 (hole)        5 -3.64686e-02     -5.46e-11\npolygon 23              71  8.18750e+03      1.23e-05\npolygon 24 (hole)        6 -8.37554e-01     -1.25e-09\npolygon 25 (hole)       38 -7.79904e+03     -1.17e-05\npolygon 26 (hole)        3 -3.41897e-05     -5.12e-14\npolygon 27 (hole)        3 -3.65499e-03     -5.47e-12\npolygon 28 (hole)        3 -4.95057e-02     -7.41e-11\npolygon 29              91  1.49663e+04      2.24e-05\npolygon 30 (hole)        5 -2.92235e-04     -4.37e-13\npolygon 31 (hole)        3 -7.43616e-06     -1.11e-14\npolygon 32 (hole)      270 -1.21455e+03     -1.82e-06\npolygon 33 (hole)       19 -4.39650e+00     -6.58e-09\npolygon 34 (hole)       35 -1.38385e+02     -2.07e-07\npolygon 35 (hole)       23 -1.99656e+01     -2.99e-08\npolygon 36              40  1.38607e+04      2.07e-05\npolygon 37 (hole)       41 -6.00381e+03     -8.98e-06\npolygon 38 (hole)        7 -1.40546e-01     -2.10e-10\npolygon 39 (hole)       11 -8.36705e+01     -1.25e-07\npolygon 40 (hole)        3 -2.33435e-03     -3.49e-12\npolygon 41              45  2.51218e+03      3.76e-06\npolygon 42             139  3.22293e+03      4.82e-06\npolygon 43             148  3.10395e+03      4.64e-06\npolygon 44 (hole)        4 -1.72650e-04     -2.58e-13\npolygon 45              75  1.73526e+04      2.60e-05\npolygon 46              83  5.28920e+03      7.91e-06\npolygon 47             106  3.04104e+03      4.55e-06\npolygon 48              71  5.63061e+03      8.43e-06\npolygon 49              10  1.99717e+02      2.99e-07\npolygon 50 (hole)        3 -1.37223e-02     -2.05e-11\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units\n                     (53270 x 28810 units)\nWindow area = 668316000 square units\nFraction of frame area: 0.435\n\n\nWith that, we can finally plot the point data onto the map.\n\noriginSG = origin_ppp[sg_owin]\n\nplot(originSG)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#fixed-and-adaptive-kde-bandwidths",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#fixed-and-adaptive-kde-bandwidths",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Fixed and Adaptive KDE bandwidths",
    "text": "Fixed and Adaptive KDE bandwidths\nFor a fixed bandwidth, we will be fixing the radius at 600m.\n\nkde_originSG_600 <- density(originSG_km, sigma=0.6, edge=TRUE, kernel=\"disc\")\nplot(kde_originSG_600)\n\n\n\n\nTypically, a fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units. To get around this, we can use an adaptive bandwidth instead.\n\nkde_originSG_adaptive <- adaptive.density(originSG_km, method=\"kernel\")\nplot(kde_originSG_adaptive)\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_originSG_600, main = \"Fixed bandwidth\")\nplot(kde_originSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\nConversion to raster via grid object\nIn order to fully visualise KDE in tmap, we would need to transform it into raster data. Before that, we need to convert it into a grid object\n\ngridded_kde_origins_bw <- as.SpatialGridDataFrame.im(kde_originSG_600)\nspplot(gridded_kde_origins_bw)\n\n\n\n\nNow, we can convert it to raster data.\n\nkde_originsSG_bw_raster <- raster(gridded_kde_origins_bw)\n\nNote that there is no CRS to this data, so we will need to assign it on our own\n\nprojection(kde_originsSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_originsSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.173372e-13, 353.656  (min, max)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-study-areas",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Extracting study areas",
    "text": "Extracting study areas\nHaving seen the traditional KDE of Grab origin points across, Singapore, we can identify the subzones where hotspots are located at and extract them for closer analysis.\n\npar(mfrow=c(1,2))\nplot(gridded_kde_origins_bw)\n\n\n\nplot(CoastalOutline[\"SUBZONE_N\"])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-pattern-observations",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-pattern-observations",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Spatial pattern observations",
    "text": "Spatial pattern observations\nFrom the raster map of the island, we can make the following observations.\n\nThere are 5 major clusters where Grab drivers begin their trips from\nThe cluster with the most observations is located in the east, spread across Tampines and Changi planning areas\nThe cluster with the second most observations is located in the central area, largely covering the Downtown Core\nThe other three clusters cover Jurong East and West, Choa Chu Kang, and Woodlands planning areas"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#comparing-spatial-point-patterns",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#comparing-spatial-point-patterns",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Comparing Spatial Point patterns",
    "text": "Comparing Spatial Point patterns\n\nExtracting study areas\nHaving seen the traditional KDE of Grab origin points across, Singapore, we can identify the planning areas where hotspots are located and extract them for closer analysis.\nBased on the raster data, I will be extracting the following planning areas:\n\nCHANGI\nTAMPINES\nDOWNTOWN CORE\nWOODLANDS\n\nNote that to do this, we do need CoastalOutline layer to be a SpatialObject first.\n\ncc = CoastalOutline[CoastalOutline$PLN_AREA_N == \"CHOA CHU KANG\",]\ndt = CoastalOutline[CoastalOutline$PLN_AREA_N == \"DOWNTOWN CORE\",]\nwl = CoastalOutline[CoastalOutline$PLN_AREA_N == \"WOODLANDS\",]\ntp = CoastalOutline[CoastalOutline$PLN_AREA_N == \"TAMPINES\",]\n\nNext, we can convert these objects into owin objects via the same process as before\n\ncc_spa <- as_Spatial(cc)\ntp_spa <- as_Spatial(tp)\nwl_spa <- as_Spatial(wl)\ndt_spa <- as_Spatial(dt)\n\ncc_sp = as(cc_spa, \"SpatialPolygons\")\ntp_sp = as(tp_spa, \"SpatialPolygons\")\nwl_sp = as(wl_spa, \"SpatialPolygons\")\ndt_sp = as(dt_spa, \"SpatialPolygons\")\n\ncc_owin = as(cc_sp, \"owin\")\ntp_owin = as(tp_sp, \"owin\")\nwl_owin = as(wl_sp, \"owin\")\ndt_owin = as(dt_sp, \"owin\")\n\nFollowing this, we combine it to the origin_ppp layer to extract relevant Grab data.\n\norigins_cc_owin = origin_ppp[cc_owin]\norigins_tp_owin = origin_ppp[tp_owin]\norigins_wl_owin = origin_ppp[wl_owin]\norigins_dt_owin = origin_ppp[dt_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre\n\norigins_cc_owin_km = rescale(origins_cc_owin, 1000, \"km\")\norigins_tp_owin_km = rescale(origins_tp_owin, 1000, \"km\")\norigins_wl_owin_km = rescale(origins_wl_owin, 1000, \"km\")\norigins_dt_owin_km = rescale(origins_dt_owin, 1000, \"km\")\n\nWe can now plot the four study areas again to see the spatial distribution of Grab origin points.\n\npar(mfrow=c(2,2))\nplot(origins_cc_owin_km, main=\"Choa Chu Kang\")\nplot(origins_tp_owin_km, main=\"Tampines\")\nplot(origins_wl_owin_km, main=\"Woodlands\")\nplot(origins_dt_owin_km, main=\"Downtown Core\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysing-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysing-study-areas",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Analysing study areas",
    "text": "Analysing study areas\nNow, we can compute the KDE of each planning areas using the methods we used for the entirety of Singapore.\nNote that we are using bw.scott for this instead of bw.diggle.\n\n\nCode\npar(mfrow=c(2,2))\nplot(density(origins_cc_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\nplot(density(origins_tp_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\nplot(density(origins_wl_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Woodlands\")\n\nplot(density(origins_dt_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Downtown Core\")\n\n\n\n\n\nWe can also compute the fixed bandwidth for these planning areas. For this we will be using a tighter bandwidth of 300m, or half of the previously used bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(origins_cc_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\nplot(density(origins_tp_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\nplot(density(origins_wl_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Woodlands\")\n\nplot(density(origins_dt_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Downtown Core\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#confirmatory-analysis-nearest-neighbour",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#confirmatory-analysis-nearest-neighbour",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Confirmatory analysis: Nearest Neighbour",
    "text": "Confirmatory analysis: Nearest Neighbour\nOne way that we can analyse and describe the distribution of spatial point patterns is via the Nearest Neighbour analysis using clarkevans.test() of statspat.\nFor this to work, we will be using the following hypothesis:\nHo = The distribution of Grab ride origins are randomly distributed.\nH1= The distribution of Grab ride origins are not randomly distributed.\nThe 95% confident interval will be used.\n\nClark and Evans Test: whole island\n\nclarkevans.test(originSG,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  originSG\nR = 0.28003, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Choa Chu Kang\n\nclarkevans.test(origins_cc_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_cc_owin\nR = 0.34217, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Tampines\n\nclarkevans.test(origins_tp_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_tp_owin\nR = 0.32408, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Woodlands\n\nclarkevans.test(origins_wl_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_wl_owin\nR = 0.31779, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Downtown Core\n\nclarkevans.test(origins_dt_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_dt_owin\nR = 0.47245, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\nIn order to conduct Network Kernel Density Estimation (NKDE), we will need a road network. For this section, we will be doing this analysis by planning area.\nFirstly, we should clean up the data before extracting according to planning area. According to the document that is attached to the data from OpenStreetMap, some of the roads labelled are not roads that cars can travel on, such as pedestrian walkways. We will need to filter out the following classes from the fclass column:\n\npedestrian\nbusway\nbridleway\ncycleway\nfootway\npath\nsteps\n\n\nsg_roads_clean <- sg_roads %>%\n              filter(fclass !=\"pedestrian\") %>%\n              filter(fclass !=\"busway\") %>%\n              filter(fclass !=\"bridleway\") %>%\n              filter(fclass !=\"cycleway\") %>%\n              filter(fclass !=\"footway\") %>%\n              filter(fclass !=\"path\") %>%\n              filter(fclass !=\"steps\")\n\nNext, we can extract the roads for each planning area.\n\nroad_cc <- st_intersection(sg_roads_clean, cc)\nroad_tp <- st_intersection(sg_roads_clean, tp)\nroad_wl <- st_intersection(sg_roads_clean, wl)\nroad_dt <- st_intersection(sg_roads_clean, dt)\n\n\nroad_cc\n\nSimple feature collection with 3163 features and 16 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 16806.03 ymin: 39012.19 xmax: 19973.64 ymax: 43036.12\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      osm_id code      fclass                   name  ref oneway maxspeed layer\n608 22721844 5113     primary      Choa Chu Kang Way <NA>      F       60     0\n611 22721847 5115    tertiary Choa Chu Kang Avenue 1 <NA>      F       50     0\n617 22732932 5122 residential Choa Chu Kang Avenue 2 <NA>      B       50     0\n619 22732934 5122 residential       Hong San Terrace <NA>      B       50     0\n620 22732935 5122 residential          Hong San Walk <NA>      F       50     0\n621 22732936 5122 residential          Hong San Walk <NA>      B       50     0\n686 22752008 5113     primary     Choa Chu Kang Road <NA>      F       60     0\n688 22752010 5113     primary      Choa Chu Kang Way <NA>      F       60     0\n689 22752011 5113     primary      Choa Chu Kang Way <NA>      F       60     0\n692 22752085 5113     primary         Brickland Road <NA>      F       60     0\n    bridge tunnel SUBZONE_N SUBZONE_C    PLN_AREA_N PLN_AREA_C    REGION_N\n608      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n611      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n617      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n619      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n620      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n621      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n686      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n688      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n689      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n692      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n    REGION_C                       geometry\n608       WR LINESTRING (19142.48 39802....\n611       WR LINESTRING (18158.17 39825....\n617       WR LINESTRING (18187.23 40237....\n619       WR LINESTRING (18287.68 39877....\n620       WR LINESTRING (18485.43 39930....\n621       WR LINESTRING (18457.67 39987....\n686       WR LINESTRING (19142.48 39802....\n688       WR LINESTRING (19151.49 39807....\n689       WR LINESTRING (19145.42 39799....\n692       WR LINESTRING (18564.37 39021....\n\n\nNote how it is geometry type geometry and not a linestring. We can convert them with the following code chunk:\n\nroad_cc <- road_cc %>%\n  st_cast(\"LINESTRING\")\n\nroad_tp <- road_tp %>%\n  st_cast(\"LINESTRING\")\n\nroad_wl <- road_wl %>%\n  st_cast(\"LINESTRING\")\n\nroad_dt <- road_dt %>%\n  st_cast(\"LINESTRING\")\n\nFinally, in order to plot the points onto a map, we will need to extract the Grab origin points separately.\n\norigin_cc <- st_intersection(origins_sf, cc)\norigin_tp <- st_intersection(origins_sf, tp)\norigin_wl <- st_intersection(origins_sf, wl)\norigin_dt <- st_intersection(origins_sf, dt)\n\nWe can now plot this on a map together with the owin containing all events within the subzone. Below is an example using Tampines planning area.\n\ntmap_mode('view')\ntm_shape(origin_tp)+\n  tm_dots() +\n  tm_shape(road_tp) +\n  tm_lines()\n\n\n\n\n\ntmap_mode('plot')\n\nWe can also plot the individual network.\n\nplot(road_tp[\"fclass\"])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-lixels-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-lixels-object",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Preparing lixels object",
    "text": "Preparing lixels object\nTo conduct NKDE, we will need to convert the road network into a lixels object. To do this, we first need to segment the lines in a network.\n\n\n\n\n\n\nNote\n\n\n\nWhy use 750m? Based off a study by NUS that the maximum walking distance people are willing to walk is 750m. Since we use 750m, the middle distance is 375m (half of the bandwidth).\n\n\n\n#|code-fold: True\n\nlixel_cc <- lixelize_lines(road_cc,\n                         750,\n                         mindist = 375)\n\nlixel_tp <- lixelize_lines(road_tp,\n                         750,\n                         mindist = 375)\n\nlixel_wl <- lixelize_lines(road_wl,\n                         750,\n                         mindist = 375)\n\nlixel_dt <- lixelize_lines(road_dt,\n                         750,\n                         mindist = 375)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#generating-line-centre-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#generating-line-centre-points",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Generating line centre points",
    "text": "Generating line centre points\nNext, we generate the centroids of each line to ensure that they are consistent.\n\ncentroid_cc <- lines_center(lixel_cc)\ncentroid_tp <- lines_center(lixel_tp)\ncentroid_wl <- lines_center(lixel_wl)\ncentroid_dt <- lines_center(lixel_dt)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-nkde",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Performing NKDE",
    "text": "Performing NKDE\nWith both centroids and lixels, we can finally perform NKDE.\n\n\nCode\ndensity_cc <- nkde(road_cc, \n                  events = origin_cc,\n                  w = rep(1,nrow(origin_cc)),\n                  samples = centroid_cc,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ndensity_tp <- nkde(road_tp, \n                  events = origin_tp,\n                  w = rep(1,nrow(origin_tp)),\n                  samples = centroid_tp,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ndensity_wl <- nkde(road_wl, \n                  events = origin_wl,\n                  w = rep(1,nrow(origin_wl)),\n                  samples = centroid_wl,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ndensity_dt <- nkde(road_dt, \n                  events = origin_dt,\n                  w = rep(1,nrow(origin_dt)),\n                  samples = centroid_dt,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-nkde",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Visualising NKDE",
    "text": "Visualising NKDE\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\n\nCode\ncentroid_cc$density <- density_cc\nlixel_cc$density <- density_cc\n\ncentroid_tp$density <- density_tp\nlixel_tp$density <- density_tp\n\ncentroid_wl$density <- density_wl\nlixel_wl$density <- density_wl\n\ncentroid_dt$density <- density_dt\nlixel_dt$density <- density_dt\n\n\nNext, because svy21 is in meters, we will need to convert the numbers to kilometers to avoid small numbers.\n\n# rescaling to help the mapping\ncentroid_cc$density <- centroid_cc$density*1000\nlixel_cc$density <- lixel_cc$density*1000\n\ncentroid_tp$density <- centroid_tp$density*1000\nlixel_tp$density <- lixel_tp$density*1000\n\ncentroid_wl$density <- centroid_wl$density*1000\nlixel_wl$density <- lixel_wl$density*1000\n\ncentroid_dt$density <- centroid_dt$density*1000\nlixel_dt$density <- lixel_dt$density*1000\n\nNow, we can visualise the network. For the sake of being able to see the road network, I will not be plotting the point data.\n\ntmap_mode('view')\ntm_shape(lixel_cc)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixel_tp)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixel_wl)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixel_dt)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')"
  }
]