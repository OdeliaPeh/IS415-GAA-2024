[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this study, we apply appropriate spatial point patterns analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore and describe the spatial patterns revealed by kernel density maps."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Aspatial data",
    "text": "Aspatial data\n\nGrab Posisi data\nFirst, the data needs to be imported into RStudio. In this exercise, we will need to import all of the data in order to observe the temporal distribution.\n\ndf <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00000.parquet\")\ndf1 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00001.parquet\")\ndf2 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00002.parquet\")\ndf3 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00003.parquet\")\ndf4 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00004.parquet\")\ndf5 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00005.parquet\")\ndf6 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00006.parquet\")\ndf7 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00007.parquet\")\ndf8 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00008.parquet\")\ndf9 <- read_parquet(file=\"data/aspatial/GrabPosisi/part-00009.parquet\")\n\n\nCombining the data\nAll of the data covers 2 weeks of Grab rides, but they are jumbled up. In order to accurately extract the origin and destination points, we need to combine everything into a singular data frame.\n\nall_grab <- df %>%\n  full_join(df1) %>%\n  full_join(df2) %>%\n  full_join(df3) %>%\n  full_join(df4) %>%\n  full_join(df5) %>%\n  full_join(df6) %>%\n  full_join(df7) %>%\n  full_join(df8) %>%\n  full_join(df9)\n\n\n\nData handling: Converting the data type of pingtimestamp to date-time\nGrab marks the date-time of each data point as a pingtimestamp. As a result, we will need to transform the data type to date-time using lubridate.\n\nall_grab$pingtimestamp <- as_datetime(all_grab$pingtimestamp)\n\n\n\nData handling: Extracting trip origins\nNow, we extract the trip origin locations and derive 3 new columns for weekday, starting hour and day of month into a new data frame. The origin locations are derived by grouping trips according to their trj_id, arranging by the date-time and filtering for the first item in each group.\n\norigin_df <- all_grab %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label = TRUE,\n                        abbr = TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\nData handling: Extracting destinations\nTo extract trip destinations, we use a similar code as above except we filter to take the nth item out of n items in a group.\n\ndest_df <- all_grab %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==n()) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label = TRUE,\n                        abbr = TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\nWriting data as rds\nWith the data transformation done, we can now write it out as an rds for future use.\n\nwrite_rds(origin_df, \"data/rds/grab_origins.rds\")\nwrite_rds(dest_df, \"data/rds/grab_dest.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Geospatial data",
    "text": "Geospatial data\n\nSingapore Coastal outline (excluding islands)\nThis layer is derived from the Master Plan 2019 Subzone Boundary (No Sea) from data.gov. First, it needs to be imported into rstudio using st_read()\n\nmpsz_sf <- st_read(dsn = \"data/geospatial\", \n                layer = \"MPSZ-2019\")\n\nFrom the summary, it can be seen that the layer is projected to WGS84. To continue, there is the need to reproject the polygons to the correct CRS SVY21.\n\nmpsz3414_sf <- st_transform(mpsz_sf, 3414)\n\nNow, we can plot the map and view the data.\n\nplot(mpsz3414_sf[\"SUBZONE_N\"])\n\nThere are some islands in the map that lack bridges for Grab drivers to reach, such as Coney Island. However, there are other relevant islands such as Sentosa that need to be kept.\nFrom research, Grab drivers can be observed to be able to enter Sentosa and Jurong Island to pick up and drop off passengers at the current moment. However, the Jurong Island polygon in mpsz3414_sf is combined with another island Bukom. Furthermore, Grab drivers are only allowed onto the island if they have a security pass, resulting in few drivers entering and exiting the island. Therefore, I am choosing to remove Jurong Island and Bukom from the map.\nHence, the islands that need to be excluded from the map are:\n\nConey Island\nSouthern Group\nNorth-Eastern islands (including Pulau Ubin: Grab drivers can only pick up and drop off passengers at the ferry terminal)\nSudong\nSemakau\nJurong Island and Bukom\n\nTo remove these, I’ve chosen to filter them out by name. This is because Sentosa and Jurong Island are also labelled as “islands” and would otherwise be caught.\n\nmain_island <- mpsz3414_sf %>%\n              filter(SUBZONE_N !=\"CONEY ISLAND\") %>%\n              filter(SUBZONE_N != \"NORTH-EASTERN ISLANDS\") %>%\n              filter(SUBZONE_N != \"SOUTHERN GROUP\") %>%\n              filter(SUBZONE_N != \"SUDONG\") %>%\n              filter(SUBZONE_N != \"SEMAKAU\") %>%\n              filter(SUBZONE_N != \"SUDONG\") %>%\n              filter(SUBZONE_N != \"JURONG ISLAND AND BUKOM\")\n\nplot(main_island[\"SUBZONE_N\"])\n\nNow, we can use st_union to get the outline of Singapore.\n\nplot(st_union(main_island))\n\n\nWriting data as rds\nWith this, we can now save the data in the rds format.\n\nwrite_rds(main_island, \"data/rds/islandOutline.rds\")\n\n\n\n\nSingapore road network\nIn order to conduct Network Kernel Density Estimation (NKDE), we will need a road network to map points onto. For Singapore’s road network, we can get data from OpenStreetMap via Geofabrik. From the documentation that comes with the download, we know that the road network is found in the gis_osm_roads_free_1 shape file.\n\nroads_all <- st_read(dsn = \"data/geospatial/openstreetmap\", \n                layer = \"gis_osm_roads_free_1\")\n\nThis data is also not projected to SVY21, which is something we will have to fix.\n\nroads_all <- st_transform(roads_all, 3414)\n\nOne issue currently is that the data includes all roads from Singapore, Malaysia and Brunei. We only want the road network for Singapore. In order to extract this, we can use st_intersection to filter for roads within Singapore based on the CoastalOutline layer (as imported from rds)\n\nsg_roads <- st_intersection(roads_all, CoastalOutline)\n\nDue to the size of the data, we will later be narrowing the scope of our investigation for NKDE to certain subzones. For now, I will save the current road network into an rds.\n\nwrite_rds(sg_roads, \"data/rds/sgroads.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-of-origins",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysis-of-origins",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Analysis of origins",
    "text": "Analysis of origins\nFirst, lets look at the distribution of origins over time using ggplot.\n\nggplot(data = origin_all_df,\n       aes(x=weekday)) +\ngeom_bar()\n\n\n\n\nAs seen above, the data is evenly distributed across all days of the week.\n\nppp object transformation\nIn order to conduct Kernel Density Estimation (KDE), we need to transform our layers into a ppp object. Before we begin that process, we will need to transform origin_all_df into an sf object using st_as_sf().\n\n\n\n\n\n\nImportant\n\n\n\nFor the “crs” argument of st_as_sf(), we need to provide it with a geodetic CRS and not a projected CRS. To transform the CRS, we can pipe the output into an st_transform() argument.\n\n\n\norigins_sf <- st_as_sf(origin_all_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\nNow, we can transform all relevant data frames into a ppp object (via transforming to Spatial/*, SpatialPoints and then ppp objects), which we can inspect using the summary function.\n\norigin_spatial <- as_Spatial(origins_sf)\norigin_sp <- as(origin_spatial, \"SpatialPoints\")\norigin_ppp <- as(origin_sp, \"ppp\")\n\nsummary(origin_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units\n\n\n\n\nDuplicate data handling\nNow, we need to check for duplicated data.\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\n\nIf we want to know how many locations have more than one point event, we can use the following:\n\nsum(multiplicity(origin_ppp) > 1)\n\n[1] 0\n\n\nAs we can see, there is no duplicate data in the ppp object.\n\n\nCreating owin object\nNext, we need to confine the analysis with a geographical area like Singapore boundary. If a study area is not defined and confined, the data points will assume it can occur within blank spaces (because technically it will spread out at random).\n\nCoastalOutline <- st_union(CoastalOutline)\nsg_owin <- as.owin(CoastalOutline)\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            13910  6.66691e+08      9.98e-01\npolygon 2              285  1.61128e+06      2.41e-03\npolygon 3               27  1.50315e+04      2.25e-05\npolygon 4 (hole)        41 -4.01660e+04     -6.01e-05\npolygon 5 (hole)       317 -5.11280e+04     -7.65e-05\npolygon 6 (hole)         3 -4.14099e-04     -6.20e-13\npolygon 7               30  2.80002e+04      4.19e-05\npolygon 8 (hole)         4 -2.86396e-01     -4.29e-10\npolygon 9 (hole)         3 -1.81439e-04     -2.71e-13\npolygon 10 (hole)        3 -8.68789e-04     -1.30e-12\npolygon 11 (hole)        3 -5.99535e-04     -8.97e-13\npolygon 12 (hole)        3 -3.04561e-04     -4.56e-13\npolygon 13 (hole)        3 -4.46076e-04     -6.67e-13\npolygon 14 (hole)        3 -3.39794e-04     -5.08e-13\npolygon 15 (hole)        3 -4.52043e-05     -6.76e-14\npolygon 16 (hole)        3 -3.90173e-05     -5.84e-14\npolygon 17 (hole)        3 -9.59850e-05     -1.44e-13\npolygon 18 (hole)        4 -2.54488e-04     -3.81e-13\npolygon 19 (hole)        4 -4.28453e-01     -6.41e-10\npolygon 20 (hole)        4 -2.18616e-04     -3.27e-13\npolygon 21 (hole)        5 -2.44411e-04     -3.66e-13\npolygon 22 (hole)        5 -3.64686e-02     -5.46e-11\npolygon 23              71  8.18750e+03      1.23e-05\npolygon 24 (hole)        6 -8.37554e-01     -1.25e-09\npolygon 25 (hole)       38 -7.79904e+03     -1.17e-05\npolygon 26 (hole)        3 -3.41897e-05     -5.12e-14\npolygon 27 (hole)        3 -3.65499e-03     -5.47e-12\npolygon 28 (hole)        3 -4.95057e-02     -7.41e-11\npolygon 29              91  1.49663e+04      2.24e-05\npolygon 30 (hole)        5 -2.92235e-04     -4.37e-13\npolygon 31 (hole)        3 -7.43616e-06     -1.11e-14\npolygon 32 (hole)      270 -1.21455e+03     -1.82e-06\npolygon 33 (hole)       19 -4.39650e+00     -6.58e-09\npolygon 34 (hole)       35 -1.38385e+02     -2.07e-07\npolygon 35 (hole)       23 -1.99656e+01     -2.99e-08\npolygon 36              40  1.38607e+04      2.07e-05\npolygon 37 (hole)       41 -6.00381e+03     -8.98e-06\npolygon 38 (hole)        7 -1.40546e-01     -2.10e-10\npolygon 39 (hole)       11 -8.36705e+01     -1.25e-07\npolygon 40 (hole)        3 -2.33435e-03     -3.49e-12\npolygon 41              45  2.51218e+03      3.76e-06\npolygon 42             139  3.22293e+03      4.82e-06\npolygon 43             148  3.10395e+03      4.64e-06\npolygon 44 (hole)        4 -1.72650e-04     -2.58e-13\npolygon 45              75  1.73526e+04      2.60e-05\npolygon 46              83  5.28920e+03      7.91e-06\npolygon 47             106  3.04104e+03      4.55e-06\npolygon 48              71  5.63061e+03      8.43e-06\npolygon 49              10  1.99717e+02      2.99e-07\npolygon 50 (hole)        3 -1.37223e-02     -2.05e-11\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units\n                     (53270 x 28810 units)\nWindow area = 668316000 square units\nFraction of frame area: 0.435\n\n\nWith that, we can finally plot the point data onto the map.\n\noriginSG = origin_ppp[sg_owin]\n\nplot(originSG)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescaling-values",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Rescaling values",
    "text": "Rescaling values\nBefore we can conduct KDE analysis, we first need to rescale the unit of measurement in originSG from metres (the unit of measurement in SVY21) to kilometres (to avoid small numbers).\n\noriginSG_km <- rescale(originSG, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-bandwidth-selection-methods",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-automatic-bandwidth-selection-methods",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Working with different automatic bandwidth selection methods",
    "text": "Working with different automatic bandwidth selection methods\nThere are 4 different automatic bandwidth selection method that we can choose: bw.diggle, bw.CvL, bw.scott and bw.ppl. For this exercise, we are using bw.diggle, or the radius selection method. We can plot all four to see which may give us better results.\n\nkde_origins_dig <- density(originSG_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nkde_origins_ppl <- density(originSG_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nkde_origins_cvl <- density(originSG_km,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nkde_origins_scott <- density(originSG_km,\n                              sigma=bw.scott,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\npar(mfrow=c(2,2))\nplot(kde_origins_dig, main = \"bw.diggle\")\nplot(kde_origins_ppl, main = \"bw.ppl\")\nplot(kde_origins_cvl, main = \"bw.cvl\")\nplot(kde_origins_scott, main = \"bw.scott\")\n\n\n\n\nWe can retrieve the bandwidth used to compute the KDE layer as well.\n\nbw.diggle(originSG)\nbw.ppl(originSG)\nbw.CvL(originSG)\nbw.scott(originSG)\n\nAs seen, bw.ppl and bw.diggle appears to give relatively similar map results which highlight a single tight cluster in the east and include up to a thousand origin points. Meanwhile, bw.cvl and bw.scott appear to use tighter radii, with bw.scott being able to better show hotspots compared to how spread out bw.cvl looks. Hence, for the rest of this exercise, we will be using bw.scott."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-kernel-methods",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#working-with-different-kernel-methods",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Working with different kernel methods",
    "text": "Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics. We can test each of these to see which kernel method provides a tighter grouping.\n\npar(mfrow=c(2,2))\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nplot(density(originSG_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\nFor this exercise, disc and quartic appear to provide us with tighter values. Hence, we will be using Disc."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-to-raster-via-grid-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conversion-to-raster-via-grid-object",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Conversion to raster via grid object",
    "text": "Conversion to raster via grid object\nIn order to fully visualise KDE in tmap, we would need to transform it into raster data. Before that, we need to convert it into a grid object\n\ngridded_kde_origins_bw <- as.SpatialGridDataFrame.im(kde_originSG_600)\nspplot(gridded_kde_origins_bw)\n\n\n\n\nNow, we can convert it to raster data.\n\nkde_originsSG_bw_raster <- raster(gridded_kde_origins_bw)\n\nNote that there is no CRS to this data, so we will need to assign it on our own\n\nprojection(kde_originsSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_originsSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.173372e-13, 353.656  (min, max)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-kde-tmap",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-kde-tmap",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Visualising KDE (tmap)",
    "text": "Visualising KDE (tmap)\n\ntm_shape(kde_originsSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#ppp-object-transformation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#ppp-object-transformation",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "ppp object transformation",
    "text": "ppp object transformation\nIn order to conduct Kernel Density Estimation (KDE), we need to transform our layers into a ppp object. Before we begin that process, we will need to transform origin_all_df into an sf object using st_as_sf().\n\n\n\n\n\n\nImportant\n\n\n\nFor the “crs” argument of st_as_sf(), we need to provide it with a geodetic CRS and not a projected CRS. To transform the CRS, we can pipe the output into an st_transform() argument.\n\n\n\norigins_sf <- st_as_sf(origin_all_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\nNow, we can transform all relevant data frames into a ppp object (via transforming to Spatial/*, SpatialPoints and then ppp objects), which we can inspect using the summary function.\n\norigin_spatial <- as_Spatial(origins_sf)\norigin_sp <- as(origin_spatial, \"SpatialPoints\")\norigin_ppp <- as(origin_sp, \"ppp\")\n\nsummary(origin_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#duplicate-data-handling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#duplicate-data-handling",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Duplicate data handling",
    "text": "Duplicate data handling\nNow, we need to check for duplicated data.\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\n\nIf we want to know how many locations have more than one point event, we can use the following:\n\nsum(multiplicity(origin_ppp) > 1)\n\n[1] 0\n\n\nAs we can see, there is no duplicate data in the ppp object."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-owin-object",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Creating owin object",
    "text": "Creating owin object\nNext, we need to confine the analysis with a geographical area like Singapore boundary. If a study area is not defined and confined, the data points will assume it can occur within blank spaces (because technically it will spread out at random).\n\nCoastalOutlineSG <- st_union(CoastalOutline)\nsg_owin <- as.owin(CoastalOutlineSG)\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            13910  6.66691e+08      9.98e-01\npolygon 2              285  1.61128e+06      2.41e-03\npolygon 3               27  1.50315e+04      2.25e-05\npolygon 4 (hole)        41 -4.01660e+04     -6.01e-05\npolygon 5 (hole)       317 -5.11280e+04     -7.65e-05\npolygon 6 (hole)         3 -4.14099e-04     -6.20e-13\npolygon 7               30  2.80002e+04      4.19e-05\npolygon 8 (hole)         4 -2.86396e-01     -4.29e-10\npolygon 9 (hole)         3 -1.81439e-04     -2.71e-13\npolygon 10 (hole)        3 -8.68789e-04     -1.30e-12\npolygon 11 (hole)        3 -5.99535e-04     -8.97e-13\npolygon 12 (hole)        3 -3.04561e-04     -4.56e-13\npolygon 13 (hole)        3 -4.46076e-04     -6.67e-13\npolygon 14 (hole)        3 -3.39794e-04     -5.08e-13\npolygon 15 (hole)        3 -4.52043e-05     -6.76e-14\npolygon 16 (hole)        3 -3.90173e-05     -5.84e-14\npolygon 17 (hole)        3 -9.59850e-05     -1.44e-13\npolygon 18 (hole)        4 -2.54488e-04     -3.81e-13\npolygon 19 (hole)        4 -4.28453e-01     -6.41e-10\npolygon 20 (hole)        4 -2.18616e-04     -3.27e-13\npolygon 21 (hole)        5 -2.44411e-04     -3.66e-13\npolygon 22 (hole)        5 -3.64686e-02     -5.46e-11\npolygon 23              71  8.18750e+03      1.23e-05\npolygon 24 (hole)        6 -8.37554e-01     -1.25e-09\npolygon 25 (hole)       38 -7.79904e+03     -1.17e-05\npolygon 26 (hole)        3 -3.41897e-05     -5.12e-14\npolygon 27 (hole)        3 -3.65499e-03     -5.47e-12\npolygon 28 (hole)        3 -4.95057e-02     -7.41e-11\npolygon 29              91  1.49663e+04      2.24e-05\npolygon 30 (hole)        5 -2.92235e-04     -4.37e-13\npolygon 31 (hole)        3 -7.43616e-06     -1.11e-14\npolygon 32 (hole)      270 -1.21455e+03     -1.82e-06\npolygon 33 (hole)       19 -4.39650e+00     -6.58e-09\npolygon 34 (hole)       35 -1.38385e+02     -2.07e-07\npolygon 35 (hole)       23 -1.99656e+01     -2.99e-08\npolygon 36              40  1.38607e+04      2.07e-05\npolygon 37 (hole)       41 -6.00381e+03     -8.98e-06\npolygon 38 (hole)        7 -1.40546e-01     -2.10e-10\npolygon 39 (hole)       11 -8.36705e+01     -1.25e-07\npolygon 40 (hole)        3 -2.33435e-03     -3.49e-12\npolygon 41              45  2.51218e+03      3.76e-06\npolygon 42             139  3.22293e+03      4.82e-06\npolygon 43             148  3.10395e+03      4.64e-06\npolygon 44 (hole)        4 -1.72650e-04     -2.58e-13\npolygon 45              75  1.73526e+04      2.60e-05\npolygon 46              83  5.28920e+03      7.91e-06\npolygon 47             106  3.04104e+03      4.55e-06\npolygon 48              71  5.63061e+03      8.43e-06\npolygon 49              10  1.99717e+02      2.99e-07\npolygon 50 (hole)        3 -1.37223e-02     -2.05e-11\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units\n                     (53270 x 28810 units)\nWindow area = 668316000 square units\nFraction of frame area: 0.435\n\n\nWith that, we can finally plot the point data onto the map.\n\noriginSG = origin_ppp[sg_owin]\n\nplot(originSG)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#fixed-and-adaptive-kde-bandwidths",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#fixed-and-adaptive-kde-bandwidths",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Fixed and Adaptive KDE bandwidths",
    "text": "Fixed and Adaptive KDE bandwidths\nFor a fixed bandwidth, we will be fixing the radius at 600m.\n\nkde_originSG_600 <- density(originSG_km, sigma=0.6, edge=TRUE, kernel=\"disc\")\nplot(kde_originSG_600)\n\n\n\n\nTypically, a fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units. To get around this, we can use an adaptive bandwidth instead.\n\nkde_originSG_adaptive <- adaptive.density(originSG_km, method=\"kernel\")\nplot(kde_originSG_adaptive)\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_originSG_600, main = \"Fixed bandwidth\")\nplot(kde_originSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\nConversion to raster via grid object\nIn order to fully visualise KDE in tmap, we would need to transform it into raster data. Before that, we need to convert it into a grid object\n\ngridded_kde_origins_bw <- as.SpatialGridDataFrame.im(kde_originSG_600)\nspplot(gridded_kde_origins_bw)\n\n\n\n\nNow, we can convert it to raster data.\n\nkde_originsSG_bw_raster <- raster(gridded_kde_origins_bw)\n\nNote that there is no CRS to this data, so we will need to assign it on our own\n\nprojection(kde_originsSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_originsSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.173372e-13, 353.656  (min, max)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-study-areas",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Extracting study areas",
    "text": "Extracting study areas\nHaving seen the traditional KDE of Grab origin points across, Singapore, we can identify the subzones where hotspots are located at and extract them for closer analysis.\n\npar(mfrow=c(1,2))\nplot(gridded_kde_origins_bw)\n\n\n\nplot(CoastalOutline[\"SUBZONE_N\"])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-pattern-observations",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-pattern-observations",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Spatial pattern observations",
    "text": "Spatial pattern observations\nFrom the raster map of the island, we can make the following observations.\n\nThere are 5 major clusters where Grab drivers begin their trips from\nThe cluster with the most observations is located in the east, spread across Tampines and Changi planning areas\nThe cluster with the second most observations is located in the central area, largely covering the Downtown Core\nThe other three clusters cover Jurong East and West, Choa Chu Kang, and Woodlands planning areas"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#comparing-spatial-point-patterns",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#comparing-spatial-point-patterns",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Comparing Spatial Point patterns",
    "text": "Comparing Spatial Point patterns\n\nExtracting study areas\nHaving seen the traditional KDE of Grab origin points across, Singapore, we can identify the planning areas where hotspots are located and extract them for closer analysis.\nBased on the raster data, I will be extracting the following planning areas:\n\nCHANGI\nTAMPINES\nDOWNTOWN CORE\nWOODLANDS\n\nNote that to do this, we do need CoastalOutline layer to be a SpatialObject first.\n\ncc = CoastalOutline[CoastalOutline$PLN_AREA_N == \"CHOA CHU KANG\",]\ndt = CoastalOutline[CoastalOutline$PLN_AREA_N == \"DOWNTOWN CORE\",]\nwl = CoastalOutline[CoastalOutline$PLN_AREA_N == \"WOODLANDS\",]\ntp = CoastalOutline[CoastalOutline$PLN_AREA_N == \"TAMPINES\",]\n\nNext, we can convert these objects into owin objects via the same process as before\n\ncc_spa <- as_Spatial(cc)\ntp_spa <- as_Spatial(tp)\nwl_spa <- as_Spatial(wl)\ndt_spa <- as_Spatial(dt)\n\ncc_sp = as(cc_spa, \"SpatialPolygons\")\ntp_sp = as(tp_spa, \"SpatialPolygons\")\nwl_sp = as(wl_spa, \"SpatialPolygons\")\ndt_sp = as(dt_spa, \"SpatialPolygons\")\n\ncc_owin = as(cc_sp, \"owin\")\ntp_owin = as(tp_sp, \"owin\")\nwl_owin = as(wl_sp, \"owin\")\ndt_owin = as(dt_sp, \"owin\")\n\nFollowing this, we combine it to the origin_ppp layer to extract relevant Grab data.\n\norigins_cc_owin = origin_ppp[cc_owin]\norigins_tp_owin = origin_ppp[tp_owin]\norigins_wl_owin = origin_ppp[wl_owin]\norigins_dt_owin = origin_ppp[dt_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre\n\norigins_cc_owin_km = rescale(origins_cc_owin, 1000, \"km\")\norigins_tp_owin_km = rescale(origins_tp_owin, 1000, \"km\")\norigins_wl_owin_km = rescale(origins_wl_owin, 1000, \"km\")\norigins_dt_owin_km = rescale(origins_dt_owin, 1000, \"km\")\n\nWe can now plot the four study areas again to see the spatial distribution of Grab origin points.\n\npar(mfrow=c(2,2))\nplot(origins_cc_owin_km, main=\"Choa Chu Kang\")\nplot(origins_tp_owin_km, main=\"Tampines\")\nplot(origins_wl_owin_km, main=\"Woodlands\")\nplot(origins_dt_owin_km, main=\"Downtown Core\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysing-study-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analysing-study-areas",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Analysing study areas",
    "text": "Analysing study areas\nNow, we can compute the KDE of each planning areas using the methods we used for the entirety of Singapore.\nNote that we are using bw.scott for this instead of bw.diggle.\n\n\nCode\npar(mfrow=c(2,2))\nplot(density(origins_cc_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\nplot(density(origins_tp_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\nplot(density(origins_wl_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Woodlands\")\n\nplot(density(origins_dt_owin_km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Downtown Core\")\n\n\n\n\n\nWe can also compute the fixed bandwidth for these planning areas. For this we will be using a tighter bandwidth of 300m, or half of the previously used bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(origins_cc_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\n\nplot(density(origins_tp_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\nplot(density(origins_wl_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Woodlands\")\n\nplot(density(origins_dt_owin_km, \n             sigma=0.3, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Downtown Core\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#confirmatory-analysis-nearest-neighbour",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#confirmatory-analysis-nearest-neighbour",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Confirmatory analysis: Nearest Neighbour",
    "text": "Confirmatory analysis: Nearest Neighbour\nOne way that we can analyse and describe the distribution of spatial point patterns is via the Nearest Neighbour analysis using clarkevans.test() of statspat.\nFor this to work, we will be using the following hypothesis:\nHo = The distribution of Grab ride origins are randomly distributed.\nH1= The distribution of Grab ride origins are not randomly distributed.\nThe 95% confident interval will be used.\n\nClark and Evans Test: whole island\n\nclarkevans.test(originSG,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  originSG\nR = 0.28003, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Choa Chu Kang\n\nclarkevans.test(origins_cc_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_cc_owin\nR = 0.34217, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Tampines\n\nclarkevans.test(origins_tp_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_tp_owin\nR = 0.32408, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Woodlands\n\nclarkevans.test(origins_wl_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_wl_owin\nR = 0.31779, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially.\n\n\n\n\nClark and Evans Test: Downtown Core\n\nclarkevans.test(origins_dt_owin,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_dt_owin\nR = 0.47245, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause p-value < 0.05, we reject H0. This means that the data is not randomly distributed spatially."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Data wrangling",
    "text": "Data wrangling\nIn order to conduct Network Kernel Density Estimation (NKDE), we will need a road network. For this section, we will be doing this analysis by planning area.\nFirstly, we should clean up the data before extracting according to planning area. According to the document that is attached to the data from OpenStreetMap, some of the roads labelled are not roads that cars can travel on, such as pedestrian walkways. We will need to filter out the following classes from the fclass column:\n\npedestrian\nbusway\nbridleway\ncycleway\nfootway\npath\nsteps\n\n\nsg_roads_clean <- sg_roads %>%\n              filter(fclass !=\"pedestrian\") %>%\n              filter(fclass !=\"busway\") %>%\n              filter(fclass !=\"bridleway\") %>%\n              filter(fclass !=\"cycleway\") %>%\n              filter(fclass !=\"footway\") %>%\n              filter(fclass !=\"path\") %>%\n              filter(fclass !=\"steps\")\n\nNext, we can extract the roads for each planning area.\n\nroad_cc <- st_intersection(sg_roads_clean, cc)\nroad_tp <- st_intersection(sg_roads_clean, tp)\nroad_wl <- st_intersection(sg_roads_clean, wl)\nroad_dt <- st_intersection(sg_roads_clean, dt)\n\n\nroad_cc\n\nSimple feature collection with 3163 features and 16 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 16806.03 ymin: 39012.19 xmax: 19973.64 ymax: 43036.12\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      osm_id code      fclass                   name  ref oneway maxspeed layer\n608 22721844 5113     primary      Choa Chu Kang Way <NA>      F       60     0\n611 22721847 5115    tertiary Choa Chu Kang Avenue 1 <NA>      F       50     0\n617 22732932 5122 residential Choa Chu Kang Avenue 2 <NA>      B       50     0\n619 22732934 5122 residential       Hong San Terrace <NA>      B       50     0\n620 22732935 5122 residential          Hong San Walk <NA>      F       50     0\n621 22732936 5122 residential          Hong San Walk <NA>      B       50     0\n686 22752008 5113     primary     Choa Chu Kang Road <NA>      F       60     0\n688 22752010 5113     primary      Choa Chu Kang Way <NA>      F       60     0\n689 22752011 5113     primary      Choa Chu Kang Way <NA>      F       60     0\n692 22752085 5113     primary         Brickland Road <NA>      F       60     0\n    bridge tunnel SUBZONE_N SUBZONE_C    PLN_AREA_N PLN_AREA_C    REGION_N\n608      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n611      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n617      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n619      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n620      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n621      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n686      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n688      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n689      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n692      F      F KEAT HONG    CKSZ02 CHOA CHU KANG         CK WEST REGION\n    REGION_C                       geometry\n608       WR LINESTRING (19142.48 39802....\n611       WR LINESTRING (18158.17 39825....\n617       WR LINESTRING (18187.23 40237....\n619       WR LINESTRING (18287.68 39877....\n620       WR LINESTRING (18485.43 39930....\n621       WR LINESTRING (18457.67 39987....\n686       WR LINESTRING (19142.48 39802....\n688       WR LINESTRING (19151.49 39807....\n689       WR LINESTRING (19145.42 39799....\n692       WR LINESTRING (18564.37 39021....\n\n\nNote how it is geometry type geometry and not a linestring. We can convert them with the following code chunk:\n\nroad_cc <- road_cc %>%\n  st_cast(\"LINESTRING\")\n\nroad_tp <- road_tp %>%\n  st_cast(\"LINESTRING\")\n\nroad_wl <- road_wl %>%\n  st_cast(\"LINESTRING\")\n\nroad_dt <- road_dt %>%\n  st_cast(\"LINESTRING\")\n\nFinally, in order to plot the points onto a map, we will need to extract the Grab origin points separately.\n\norigin_cc <- st_intersection(origins_sf, cc)\norigin_tp <- st_intersection(origins_sf, tp)\norigin_wl <- st_intersection(origins_sf, wl)\norigin_dt <- st_intersection(origins_sf, dt)\n\nWe can now plot this on a map together with the owin containing all events within the subzone. Below is an example using Tampines planning area.\n\ntmap_mode('view')\ntm_shape(origin_tp)+\n  tm_dots() +\n  tm_shape(road_tp) +\n  tm_lines()\n\n\n\n\n\ntmap_mode('plot')\n\nWe can also plot the individual network.\n\nplot(road_tp[\"fclass\"])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-lixels-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-lixels-object",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Preparing lixels object",
    "text": "Preparing lixels object\nTo conduct NKDE, we will need to convert the road network into a lixels object. To do this, we first need to segment the lines in a network.\n\n\n\n\n\n\nNote\n\n\n\nWhy use 750m? Based off a study by NUS that the maximum walking distance people are willing to walk is 750m. Since we use 750m, the middle distance is 375m (half of the bandwidth).\n\n\n\n#|code-fold: True\n\nlixel_cc <- lixelize_lines(road_cc,\n                         750,\n                         mindist = 375)\n\nlixel_tp <- lixelize_lines(road_tp,\n                         750,\n                         mindist = 375)\n\nlixel_wl <- lixelize_lines(road_wl,\n                         750,\n                         mindist = 375)\n\nlixel_dt <- lixelize_lines(road_dt,\n                         750,\n                         mindist = 375)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#generating-line-centre-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#generating-line-centre-points",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Generating line centre points",
    "text": "Generating line centre points\nNext, we generate the centroids of each line to ensure that they are consistent.\n\ncentroid_cc <- lines_center(lixel_cc)\ncentroid_tp <- lines_center(lixel_tp)\ncentroid_wl <- lines_center(lixel_wl)\ncentroid_dt <- lines_center(lixel_dt)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-nkde",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Performing NKDE",
    "text": "Performing NKDE\nWith both centroids and lixels, we can finally perform NKDE.\n\n\nCode\ndensity_cc <- nkde(road_cc, \n                  events = origin_cc,\n                  w = rep(1,nrow(origin_cc)),\n                  samples = centroid_cc,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ndensity_tp <- nkde(road_tp, \n                  events = origin_tp,\n                  w = rep(1,nrow(origin_tp)),\n                  samples = centroid_tp,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ndensity_wl <- nkde(road_wl, \n                  events = origin_wl,\n                  w = rep(1,nrow(origin_wl)),\n                  samples = centroid_wl,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\ndensity_dt <- nkde(road_dt, \n                  events = origin_dt,\n                  w = rep(1,nrow(origin_dt)),\n                  samples = centroid_dt,\n                  kernel_name = \"quartic\", \n                  bw = 300,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-nkde",
    "title": "Take Home Exercise 1: Application of Spatial Point Patterns Analysis",
    "section": "Visualising NKDE",
    "text": "Visualising NKDE\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\n\nCode\ncentroid_cc$density <- density_cc\nlixel_cc$density <- density_cc\n\ncentroid_tp$density <- density_tp\nlixel_tp$density <- density_tp\n\ncentroid_wl$density <- density_wl\nlixel_wl$density <- density_wl\n\ncentroid_dt$density <- density_dt\nlixel_dt$density <- density_dt\n\n\nNext, because svy21 is in meters, we will need to convert the numbers to kilometers to avoid small numbers.\n\n# rescaling to help the mapping\ncentroid_cc$density <- centroid_cc$density*1000\nlixel_cc$density <- lixel_cc$density*1000\n\ncentroid_tp$density <- centroid_tp$density*1000\nlixel_tp$density <- lixel_tp$density*1000\n\ncentroid_wl$density <- centroid_wl$density*1000\nlixel_wl$density <- lixel_wl$density*1000\n\ncentroid_dt$density <- centroid_dt$density*1000\nlixel_dt$density <- lixel_dt$density*1000\n\nNow, we can visualise the network. For the sake of being able to see the road network, I will not be plotting the point data.\n\ntmap_mode('view')\ntm_shape(lixel_cc)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixel_tp)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixel_wl)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixel_dt)+\n  tm_lines(col=\"density\")\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA-2024",
    "section": "",
    "text": "This is the course website of IS415 I study this term. You will find my course work on this website."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "According to the exercise, we will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#global-autocorrelation-as-taken-from-the-website",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#global-autocorrelation-as-taken-from-the-website",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Global autocorrelation (as taken from the website)",
    "text": "Global autocorrelation (as taken from the website)\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#local-autocorrelation-as-taken-from-the-website",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#local-autocorrelation-as-taken-from-the-website",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Local autocorrelation (as taken from the website)",
    "text": "Local autocorrelation (as taken from the website)\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-data",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Importing data",
    "text": "Importing data\nFirst, we read ithe Hunan shape file using st_read()\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\OdeliaPeh\\IS415-GAA-2024\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-wrangling-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-wrangling-relational-join",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Data wrangling: relational join",
    "text": "Data wrangling: relational join\nWe use left_join() to update the attribute table of the Hunan layer with some of the attributes from hunan2012 dataframe.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-i-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-i-test",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran’s I Test",
    "text": "Moran’s I Test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nComputing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gearys-c",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Geary’s C",
    "text": "Geary’s C\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nComputing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#spatial-correlogram",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\nCompute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCompute Geary’s C correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\n\n\n\n\n\nNote\n\n\n\nNote how Geary’s C uses a different method and style from Moran’s I\n\n\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#cluster-and-outlier-analysis",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Cluster and Outlier Analysis",
    "text": "Cluster and Outlier Analysis\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, you will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\nComputing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\nMapping the local Moran’s I\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\nMapping the local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\nPlotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\n\nPlotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\nPreparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)   \n\nThis is followed by centering the local Moran’s around the mean.\n\nLM_I <- localMI[,1] - mean(localMI[,1])  \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif <- 0.05\n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]>signif] <- 0\n\nIn fact, we can combine all the steps into one single code chunk as shown below:\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I <- localMI[,1]   \nsignif <- 0.05       \nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI[,5]>signif] <- 0\n\n\n\nPlotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\nGetis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\nDeriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\nComputing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-gi-statistics",
    "title": "Hands-on Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Gi Statistics",
    "text": "Computing Gi Statistics\n\nGi statistics using fixed distance\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\nMapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\nGi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\nMapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  }
]